{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afbc9ee5",
   "metadata": {},
   "source": [
    "### Prepare Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2237b0",
   "metadata": {},
   "source": [
    "<p>\n",
    "<a href='http://www.paulgraham.com/articles.html' target='_blank'>Paul Graham essays</a>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91009e7d",
   "metadata": {},
   "source": [
    "## RNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eabdafff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b3d19d",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8ee540",
   "metadata": {},
   "source": [
    "<p>\n",
    " Let's take paulgraham essays and try to create language model using simple vanilla RNN.<br/>\n",
    " To keep it simple we use character level model to avoid big vocab size issue.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c6d745a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./paulgraham_essays.json', 'r') as f:\n",
    "    data = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "abacf08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "txts = \"\"\n",
    "for ele in data:\n",
    "    txts += ele + '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b0f2826",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size:103, data char size: 1845065\n"
     ]
    }
   ],
   "source": [
    "vocab = list(set(txts))\n",
    "vocab_sz, n_char = len(vocab),len(txts)\n",
    "print(f'vocab size:{vocab_sz}, data char size: {n_char}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711da3e9",
   "metadata": {},
   "source": [
    "<p> Data char size is too big, let's try first small number char size by truncating </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25eb50aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size:69, data char size: 10000\n"
     ]
    }
   ],
   "source": [
    "max_sz = 10000\n",
    "txts = txts[:max_sz]\n",
    "vocab = list(set(txts))\n",
    "vocab_sz, n_char = len(vocab),len(txts)\n",
    "print(f'vocab size:{vocab_sz}, data char size: {n_char}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a1f677",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c431dbc3",
   "metadata": {},
   "source": [
    "<p style=\"line-height:2\">\n",
    "   * Our model is a simple RNN (Recurrent Nueural Netwrok) model. <br/>\n",
    "   * RNN is speicific way of arranging neural network layers so that it can model sequence data like texts. <br/>\n",
    "   * Usual feed-forward neural network (FNN) has problem with handling sequence data like texts, the problem is keeping track of dependencies in the sequence so that it can produce next element in the sequence, in the case of texts it may be next word/char.<br/>\n",
    "   * problem-1: in FNN sequence order got destroyed, but order is important in sequence data like texts. <br/>\n",
    "   * problem-2: FNN takes entire sequence in a single go but we need to input the sequence one element/char at a time and get the next predicted element/char in the sequence, so that we can train our model using the predicted element/char against actual next element/char in the sequence. if we want to do this in FNN then it will require variying input size but FNN requires pre-defined input and output size.<br/>\n",
    "   * So basically RNN is just a modified version of FNN that can handle above mentioned problems and also able to train params using backpropagation.<br/>\n",
    "   \n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06eb56de",
   "metadata": {},
   "source": [
    "#### Input and Label Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62ef962",
   "metadata": {},
   "source": [
    "<p style=\"line-height:2\">\n",
    "    * We can't input entire sequence data into network, we need to split the sequence into multiple small chunks of sequence so that our system can handle one at a time.<br/>\n",
    "    * Our goal for the model is it should take one element at a time and produce next element, so label will be the next element given the previous element.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "42b72e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_sz = 25\n",
    "inputs = txts[0:seq_sz]\n",
    "targets = txts[1:seq_sz+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ff323d78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'January 2023\\n\\n(Someone fe'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "84c8d3cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'anuary 2023\\n\\n(Someone fed'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "61d27307",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dls(txts, n_char, seq_sz):\n",
    "    for i in range(n_char):\n",
    "        if (i+seq_sz+1)>n_char:\n",
    "            return ([], [])\n",
    "        yield (txts[i:i+seq_sz], txts[i+1:i+1+seq_sz])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cbf30d",
   "metadata": {},
   "source": [
    "#### Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10281100",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af48b78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0dac1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python_main] *",
   "language": "python",
   "name": "conda-env-python_main-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
