{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecd5b516",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9de4e01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export \n",
    "import torch,math\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from operator import attrgetter\n",
    "import fastcore.all as fc\n",
    "from collections.abc import Mapping\n",
    "from copy import copy\n",
    "from torch import optim\n",
    "from fastprogress import progress_bar,master_bar\n",
    "from miniai.conv import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d03c38a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import torchvision.transforms.functional as TF\n",
    "from miniai.datasets import *\n",
    "from torch import nn,tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8082d77d",
   "metadata": {},
   "source": [
    "### Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d578a950",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset fashion_mnist (/Users/arun/.cache/huggingface/datasets/fashion_mnist/fashion_mnist/1.0.0/0a671f063342996f19779d38c0ab4abef9c64f757b35af8134b331c294d7ba48)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbf0f999a88543b28617943dec05b89b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_x,_y = 'image','label'\n",
    "name = 'fashion_mnist'\n",
    "dr = load_dataset(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0153971f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@inplace\n",
    "def transformi(b):\n",
    "    b[_x] = [torch.flatten(TF.to_tensor(e)) for e in b[_x]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6be72a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 1024\n",
    "tds = dr.with_transform(transformi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "780b1e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = DataLoaders.from_dd(tds, batch_size=bs)\n",
    "xb,yb = next(iter(dls.train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2c67db2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Learner:\n",
    "    def __init__(self, model, dls, loss_func, lr, opt_func=optim.SGD):\n",
    "        fc.store_attr()\n",
    "    \n",
    "    def one_batch(self):\n",
    "        self.xb,self.yb = to_device(self.batch)\n",
    "        self.preds = self.model(self.xb)\n",
    "        self.loss = self.loss_func(self.preds, self.yb)\n",
    "        if self.model.training:\n",
    "            self.loss.backward()\n",
    "            self.opt.step()\n",
    "            self.opt.zero_grad()\n",
    "        with torch.no_grad():\n",
    "            self.calc_stats()\n",
    "    \n",
    "    def calc_stats(self):\n",
    "        acc = (self.preds.argmax(dim=1) == self.yb).float().sum()\n",
    "        self.accs.append(acc)\n",
    "        n = len(self.xb)\n",
    "        self.losses.append(self.loss*n)\n",
    "        self.ns.append(n)\n",
    "    \n",
    "    def one_epoch(self, train):\n",
    "        self.model.training = train\n",
    "        self.dl = self.dls.train if train else self.dls.valid\n",
    "        for self.num,self.batch in enumerate(self.dl):\n",
    "            self.one_batch()\n",
    "        n = sum(self.ns)\n",
    "        print(self.epoch, self.model.training, sum(self.losses).item()/n, sum(self.accs).item()/n)\n",
    "    \n",
    "    def fit(self, n_epochs):\n",
    "        self.accs,self.losses,self.ns = [],[],[]\n",
    "        self.n_epochs = n_epochs\n",
    "        self.model.to(def_device)\n",
    "        self.opt = self.opt_func(self.model.parameters(), lr=self.lr)\n",
    "        for self.epoch in range(n_epochs):\n",
    "            self.one_epoch(True)\n",
    "            with torch.no_grad():\n",
    "                self.one_epoch(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a94f104d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n,nh,nout = 28*28,50,10\n",
    "model = nn.Sequential(nn.Linear(n, nh), nn.ReLU(), nn.Linear(nh, nout))\n",
    "learner = Learner(model, dls, lr=0.2, loss_func=F.cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5cdb562e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 True 1.143631640625 0.6196166666666667\n",
      "0 False 1.09259609375 0.6317714285714285\n",
      "1 True 0.9109576322115385 0.6837538461538462\n",
      "1 False 0.8907945870535714 0.69035\n"
     ]
    }
   ],
   "source": [
    "learner.fit(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b01c643",
   "metadata": {},
   "source": [
    "### Basic Callbacks Listener"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6d5e46d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class CancelFitException(Exception): pass\n",
    "class CancelBatchException(Exception): pass\n",
    "class CancelEpochException(Exception): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "74509a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class Callback():\n",
    "    order = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f7522417",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def run_cbs(cbs, method_nm, learn=None):\n",
    "    for cb in sorted(cbs, key=attrgetter('order')):\n",
    "        method = getattr(cb, method_nm, None)\n",
    "        if method is not None:\n",
    "            method(learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ce426898",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompletionCB(Callback):\n",
    "    def before_fit(self, learn):\n",
    "        self.count = 0\n",
    "    \n",
    "    def before_batch(self, learn):\n",
    "        self.count += 1\n",
    "    \n",
    "    def after_fit(self, learn):\n",
    "        print(f'Completed {self.count} batches')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9d5e14e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 2 batches\n"
     ]
    }
   ],
   "source": [
    "cbs = [CompletionCB()]\n",
    "run_cbs(cbs, 'before_fit')\n",
    "run_cbs(cbs, 'before_batch')\n",
    "run_cbs(cbs, 'before_batch')\n",
    "run_cbs(cbs, 'after_fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7229d5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Learner:\n",
    "    def __init__(self, model, dls, lr, cbs, loss_func, opt_func=optim.SGD):\n",
    "        fc.store_attr()\n",
    "    \n",
    "    def one_batch(self):\n",
    "        self.xb,self.yb = self.batch\n",
    "        self.preds = self.model(self.xb)\n",
    "        self.loss = self.loss_func(self.preds, self.yb)\n",
    "        if self.model.training:\n",
    "            self.loss.backward()\n",
    "            self.opt.step()\n",
    "            self.opt.zero_grad()\n",
    "    \n",
    "    def one_epoch(self, train):\n",
    "        self.model.training = train\n",
    "        self.dl = self.dls.train if train else self.dls.valid\n",
    "        try:\n",
    "            self.callback('before_epoch')\n",
    "            for self.num,self.batch in enumerate(self.dl):\n",
    "                    try:\n",
    "                        self.callback('before_batch')\n",
    "                        self.one_batch()\n",
    "                        self.callback('after_batch')\n",
    "                    except CancelBatchException:\n",
    "                        pass\n",
    "            self.callback('after_epoch')\n",
    "        except CancelEpochException:\n",
    "            pass\n",
    "    \n",
    "    def fit(self, n_epochs):\n",
    "        self.n_epochs = n_epochs\n",
    "        self.epochs = range(n_epochs)\n",
    "        self.opt = self.opt_func(self.model.parameters(), lr=self.lr)\n",
    "        try:\n",
    "            self.callback('before_fit')\n",
    "            for self.epoch in self.epochs:\n",
    "                self.one_epoch(True)\n",
    "                self.one_epoch(False)\n",
    "            self.callback('after_fit')\n",
    "        except CancelFitException:\n",
    "            pass\n",
    "    \n",
    "    def callback(self, method_nm):\n",
    "        run_cbs(self.cbs, method_nm, self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "81c93889",
   "metadata": {},
   "outputs": [],
   "source": [
    "n,nh,nout = 28*28,50,10\n",
    "def get_model():\n",
    "    return nn.Sequential(nn.Linear(n,nh), nn.ReLU(), nn.Linear(nh, nout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "637762a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 64 batches\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "cbs = [CompletionCB()]\n",
    "learner = Learner(model, dls, loss_func=F.cross_entropy, lr=0.2, cbs=cbs)\n",
    "learner.fit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0d567a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class SingleBatchCB(Callback):\n",
    "    order = 1\n",
    "    def after_batch(self, learn):\n",
    "        raise CancelFitException()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f69b1679",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()\n",
    "learner = Learner(model, dls, loss_func=F.cross_entropy, lr=0.2, cbs=[SingleBatchCB(), CompletionCB()])\n",
    "learner.fit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee16740",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3b357f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metric:\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.vals,self.ns = [],[]\n",
    "    \n",
    "    def add(self, inps, targs=None, n=1):\n",
    "        self.last = self.calc(inps, targs)\n",
    "        self.vals.append(self.last)\n",
    "        self.ns.append(n)\n",
    "    \n",
    "    @property\n",
    "    def value(self):\n",
    "        ns = tensor(self.ns)\n",
    "        return (tensor(self.vals)*ns).sum()/ns.sum()\n",
    "    \n",
    "    def calc(self, inps, targs):\n",
    "        return inps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9e5dd316",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Accuracy(Metric):\n",
    "    def calc(self, inps, targs):\n",
    "        return (inps==targs).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8db51677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4500)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = Accuracy()\n",
    "acc.add(tensor([0, 1, 2, 0, 1, 2]), tensor([0, 1, 1, 2, 1, 0]))\n",
    "acc.add(tensor([1, 1, 2, 0, 1]), tensor([0, 1, 1, 2, 1]))\n",
    "acc.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b70e19a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.6176), 0.62)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = Metric()\n",
    "loss.add(0.6, n=32)\n",
    "loss.add(0.9, n=2)\n",
    "loss.value, round((0.6*32+0.9*2)/(32+2), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ae017b",
   "metadata": {},
   "source": [
    "### Some Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "94b00ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "from torcheval.metrics import MulticlassAccuracy,Mean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f201bb03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5000)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric = MulticlassAccuracy()\n",
    "metric.update(tensor([0, 2, 1, 3]), tensor([0, 1, 2, 3]))\n",
    "metric.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ed1e7209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(nan)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric.reset()\n",
    "metric.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "acced515",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def to_cpu(x):\n",
    "    if isinstance(x, Mapping):\n",
    "        return {k: to_cpu(v) for k,v in x.items()}\n",
    "    if isinstance(x, list):\n",
    "        return [to_cpu(e) for e in x]\n",
    "    if isinstance(x, tuple):\n",
    "        return tuple(to_cpu(list(x)))\n",
    "    res = x.detach().cpu()\n",
    "    return res.float() if res.dtype==torch.float16 else res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "463360cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class MetricsCB(Callback):\n",
    "    def __init__(self, *ms, **metrics):\n",
    "        for e in ms:\n",
    "            metrics[type(e).__name__] = e\n",
    "        self.metrics = metrics\n",
    "        self.all_metrics = copy(self.metrics)\n",
    "        self.all_metrics['losss'] = self.loss = Mean()\n",
    "    \n",
    "    def before_epoch(self, learn):\n",
    "        [e.reset() for e in self.all_metrics.values()]\n",
    "    \n",
    "    def before_fit(self, learn):\n",
    "        learn.metrics = self\n",
    "    \n",
    "    def after_batch(self, learn):\n",
    "        x,y,*_ = to_cpu(learn.batch)\n",
    "        for m in self.metrics.values():\n",
    "            m.update(to_cpu(learn.preds), y)\n",
    "        self.loss.update(to_cpu(learn.loss), weight=len(x))\n",
    "    \n",
    "    def after_epoch(self, learn):\n",
    "        log = {k:f'{m.compute():.3f}' for k,m in self.all_metrics.items()}\n",
    "        log['epoch'] = learn.epoch\n",
    "        log['train'] = 'train' if learn.model.training else 'eval'\n",
    "        self._log(log)\n",
    "    \n",
    "    def _log(self, d):\n",
    "        print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "174e44f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class DeviceCB(Callback):\n",
    "    def __init__(self, device=def_device):\n",
    "        fc.store_attr()\n",
    "    \n",
    "    def before_fit(self, learn):\n",
    "        if hasattr(learn.model, 'to'):\n",
    "            learn.model.to(self.device)\n",
    "    \n",
    "    def before_batch(self, learn):\n",
    "        learn.batch = to_device(learn.batch, device=self.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9ac2a95e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': '0.606', 'losss': '1.160', 'epoch': 0, 'train': 'train'}\n",
      "{'accuracy': '0.725', 'losss': '0.763', 'epoch': 0, 'train': 'eval'}\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "metrics = MetricsCB(accuracy=MulticlassAccuracy())\n",
    "learn = Learner(model, dls, lr=0.2, loss_func=F.cross_entropy, cbs=[metrics, DeviceCB()])\n",
    "learn.fit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b400a416",
   "metadata": {},
   "source": [
    "### Flexible Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "68269f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class ProgressCB(Callback):\n",
    "    order = MetricsCB.order+1\n",
    "    def __init__(self, plot=False): self.plot = plot\n",
    "    def before_fit(self, learn):\n",
    "        learn.epochs = self.mbar = master_bar(learn.epochs)\n",
    "        self.first = True\n",
    "        if hasattr(learn, 'metrics'): learn.metrics._log = self._log\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "\n",
    "    def _log(self, d):\n",
    "        if self.first:\n",
    "            self.mbar.write(list(d), table=True)\n",
    "            self.first = False\n",
    "        self.mbar.write(list(d.values()), table=True)\n",
    "\n",
    "    def before_epoch(self, learn): learn.dl = progress_bar(learn.dl, leave=False, parent=self.mbar)\n",
    "    def after_batch(self, learn):\n",
    "        learn.dl.comment = f'{learn.loss:.3f}'\n",
    "        if self.plot and hasattr(learn, 'metrics') and learn.training:\n",
    "            self.losses.append(learn.loss.item())\n",
    "            if self.val_losses: self.mbar.update_graph([[fc.L.range(self.losses), self.losses],\\\n",
    "                [fc.L.range(learn.epoch).map(lambda x: (x+1)*len(learn.dls.train)), self.val_losses]])\n",
    "    \n",
    "    def after_epoch(self, learn): \n",
    "        if not learn.training:\n",
    "            if self.plot and hasattr(learn, 'metrics'): \n",
    "                self.val_losses.append(learn.metrics.all_metrics['loss'].compute())\n",
    "                self.mbar.update_graph([[fc.L.range(self.losses), self.losses],\\\n",
    "                [fc.L.range(learn.epoch+1).map(lambda x: (x+1)*len(learn.dls.train)), self.val_losses]])\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d20e068",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_main",
   "language": "python",
   "name": "python_main"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
